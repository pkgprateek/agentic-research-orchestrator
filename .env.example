# Environment Configuration Template
# Copy this to .env and fill in your API keys

# === LLM Providers ===
# OpenRouter (Primary - supports OpenAI, Claude, Gemini models)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# === Search APIs ===
# Tavily (Primary - AI-native search for agents)
TAVILY_API_KEY=your_tavily_api_key_here

# Brave Search (Optional - backup search)
# BRAVE_SEARCH_API_KEY=your_brave_api_key_here

# === Observability ===
# LangSmith (Production monitoring)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=market-intelligence-prod
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# === Application Settings ===
# Environment: development, production
ENVIRONMENT=development

# Default LLM model (via OpenRouter)
# FREE for testing (avoid costs during development):
DEFAULT_MODEL=x-ai/grok-4.1-fast:free
# Other free: meta-llama/llama-3.3-70b-instruct:free
#
# CHEAP for testing:
# DEFAULT_MODEL=openai/gpt-5-nano  # $0.05/$0.40 per 1M tokens
# DEFAULT_MODEL=openai/gpt-5-mini  # $0.25/$2.00 per 1M tokens
# DEFAULT_MODEL=google/gemini-2.5-flash-lite  # $0.10/$0.40 per 1M tokens
#
# PRODUCTION (best for final app):
# DEFAULT_MODEL=anthropic/claude-sonnet-4.5  # $3/$15 per 1M (best code/reasoning)
# DEFAULT_MODEL=google/gemini-3-pro-preview  # $2/$12 per 1M (enterprise credibility)

# Cost limits
MAX_COST_PER_RUN=2.0  # USD

# === Optional: Local LLM (Ollama) ===
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:latest